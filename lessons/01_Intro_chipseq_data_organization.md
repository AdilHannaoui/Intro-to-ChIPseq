---
title: "Introduction to ChIP-Seq and directory setup"
author: "Mary Piper, Radhika Khetani, Meeta Mistry"
date: "June 28, 2017"
---

Approximate time: 40 minutes

## Learning Objectives

- Understand the experimental setup and design for ChIP-Seq experiments
- Recognize the need for data management.
- Plan a good genomics experiment and getting started with project organization.
- Explain the ChIP-seq experiment and its objectives.

## Introduction to ChIP-Seq
Chromatin immunoprecipitation (ChIP) experiments isolate the chromatin from a cell and immunoprecipitate (IP) DNA fragments bound to a protein of interest. In ChIP-Seq, the DNA fragments are sequenced, enriched regions of DNA or peaks are determined, and over-represented sequence motifs and functional annotations can be identified. 

![chipseq_overview](../img/chipseq_overall.png)

During this session we will be performing a complete workflow for ChIP-Seq analysis, starting with experimental design and generation of the raw sequencing reads and ending with functional enrichment analyses and motif discovery.

![chipseq_workflow_general](../img/chipseq_workflow_general.png)

## Experimental design and library preparation

Several steps are involved in the library preparation of protein-bound DNA fragments for sequencing: 

![exp_workflow](../img/chipseq_experimental_workflow.png)

1. After the chromatin is isolated from the cell, proteins are cross-linked to the DNA
2. The DNA is sheared into fragments (sonication)
3. A protein-specific antibody is used to immunoprecipitate the protein-bound DNA fragments
4. The crosslink is reversed and DNA purified
5. DNA fragments are size selected and amplified using PCR


Within the DNA fragments enriched for the regions binding to a protein of interest, only a fraction correspond to actual signal. The proportion of DNA fragments containing the actual binding site of the protein depends on the **number of active binding sites, the number of starting genomes, and the efficiency of the IP**. 

In addition, when performing ChIP-Seq, some sequences may appear enriched due to the following:

- Open chromatin regions are fragmented more easily than closed regions
- Repetitive sequences might seem to be enriched (copy number inaccuracies in genome assembly)
- Uneven distribution of sequence reads across the genome

Therefore, proper controls are essential. A ChIP-Seq peak should be compared with the same region of the genome in a matched control.

![peaks](../img/chipseq_exp_peaks.png)

The same starting material should be divided to be used for both the protein-specific IP and the control. The control sample can be generated by one of the following recommended techniques: 

- No IP (input DNA) 
- No antibody ("mock IP")
- Non-specific antibody (IgG "mock IP")

![controls](../img/chipseq_exp_controls.png)

## Setting up

Since we are going to be working with this data on our remote server, **Orchestra 2 (O2)**, we first need to log onto the server. 

Type in the following command with your username to login:

```bash
ssh username@o2.hms.harvard.edu
```
> **NOTE:** This workshop assumes a basic knowledge of logging onto the O2 cluster environment. Mac users can use the "Terminal" application to login and PC users can use PuTTy or GitBash as described in the [Intro to Shell lesson](https://hbctraining.github.io/Intro-to-Shell/lessons/01_the_filesystem.html) 


Next we will start an interactive session on O2 with 2 cores (add the `-n 2`):

```bash
$ srun --pty -p short -t 0-12:00 --mem 8G -n 2 --reservation=HSPH bash
```

Make sure that your command prompt is now preceded by a character string that contains the word "compute".

To use some of the tools for the analysis you will need to have bcbio in you path, but please check that it is:

```bash
$ echo $PATH
```

If `/n/app/bcbio/tools/bin/` is not part of `$PATH`, add it by adding the following line within your `~/.bashrc` file and then run `source ~/.bashrc`:

```bash
export PATH=/n/app/bcbio/tools/bin:$PATH
```


## Data Management

> *"Data Management is the process of providing the appropriate labeling, storage, and access for data at all stages of a research project. We recognize that best practices for each of these aspects of data management can and often do change over time, and are different for different stages in the data lifecycle."*
> 
> *[- HMS Data Management Working Group](https://datamanagement.hms.harvard.edu/hms-data-management-working-group)*

<img src="../img/data_life_cycle_gouldv2.png" width="350">

The data lifecycle is not linear and you may find yourself jumping around this lifecycle throughout the course of your
project. Today we will cover some parts of this lifecycle by talking about **best practices for the Research half** of the above lifecycle. Later in this workshop we will talk a little more about the data storage. For more information about the full lifecycle and more guidelines, please look at the resources linked below.

**Resources**
* The [HMS Data Management Working Group's website](https://datamanagement.hms.harvard.edu/)
* A guide from the [Harvard library](http://guides.library.harvard.edu/dmp).

### Planning

You should approach your sequencing project in a very similar way to how you do a biological experiment, and ideally, begins with **experimental design**. We're going to assume that you've already designed a beautiful sequencing experiment to address your biological question, collected appropriate samples, and that you have enough statistical power.

During this stage it is important to keep track of how the experiment was performed and clearly tracking the source of starting materials and kits used. It is also best practice to include information about any small variations within the experiment or variation relative to standard experiments. 

### Organization

Project organization is one of the most important parts of a sequencing project, but is often overlooked in the excitement to get a first look at new data. While it's best to get yourself organized before you begin analysis, it's never too late to start.

Every computational analysis you do is going to spawn many files, and inevitability you'll want to run some of those analyses again. For each experiment you work on and analyze data for, it is considered best practice to get organized by creating a planned storage space (directory structure).

Create a `chipseq` directory and change directories into it:

```bash
$ mkdir chipseq

$ cd chipseq
```

Now that we have a project directory, we can set up the following structure within it to keep files organized.

```bash
chipseq/
├── logs/
├── meta/
├── raw_data/
├── reference_data/
├── results/
│   ├── bowtie2/
│   └── fastqc/
└── scripts/
```

```bash
$ mkdir raw_data reference_data scripts logs meta

$ mkdir -p results/fastqc results/bowtie2
```

> Note that we are using the parents flag (`-p` or `--parents`) with `mkdir` to complete the file path by creating any parent directories that do not exist. In our case, we have not yet created the `results` directory and so since it does not exist it will be created. This flag can be very useful when scripting workflows. 

**This is a generic directory structure and can be tweaked based on personal preference and analysis workflow.**

- `logs`: to keep track of the commands run and the specific parameters used, but also to have a record of any standard output that is generated while running the command. 
- `meta`: for any information that describes the samples you are using, which we refer to as [metadata](https://datamanagement.hms.harvard.edu/metadata-overview). We will discuss this in more detail as it pertains to our example dataset, later in this lesson.
- `raw_data`: for any **unmodified** (raw) data obtained prior to computational analysis here, e.g. FASTQ files from the sequencing center. We strongly recommend leaving this directory unmodified through the analysis.
- `reference_data`: for known information related to the reference genome that will be used in the analysis, e.g. genome sequence (FASTA), gene annotation file (GTF) associated with the genome.
- `results`: for output from the different tools you implement in your workflow. Create sub-folders specific to each tool/step of the workflow within this folder. 
- `scripts`: for scripts that you write and use to run analyses/workflow.


Now that we have the directory structure created, let's copy over the data to perform our quality control and alignment, including our FASTQ files and reference data files:

```bash
$ cp /n/groups/hbctraining/chip-seq/raw_fastq/*fastq raw_data/

$ cp /n/groups/hbctraining/chip-seq/reference_data/chr12* reference_data/
```

Now we are all set up for our analysis!

### Documentation

**Documentation doesn't stop at the sequencer!** Continue to maintain a lab notebook equivalent during the analysis to make your analysis reproducible and efficient.

#### Log files

In your lab notebook, you likely keep track of the different reagents and kits used for a specific protocol. Similarly, recording information about the tools and parameters is important for documenting your computational experiments. 

- Keep track of software versions
- Record information on parameters used and summary statistics at every step (e.g., how many adapters were removed, how many reads did not align)
- Save log files and console output
    - Different tools have different ways of reporting log messages and you might have to experiment a bit to figure out what output to capture. You can redirect standard output with the `>` symbol which is equivalent to `1> (standard out)`; other tools might require you to use `2>` to re-direct the `standard error` instead.
 
#### README files

After setting up the directory structure and when the analysis is running it is useful to have a **[README file](https://datamanagement.hms.harvard.edu/readme-files) within your project directory**. This file will usually contain a quick one line summary about the project and any other lines that follow will describe the files/directories found within it. An example README is shown below. Within each sub-directory you can also include README files to describe the analysis and the files that were generated.

Keeping notes on what happened in what order, and what was done, is essential for reproducible research. If you don’t keep good notes, then you will forget what you did pretty quickly, and if you don’t know what you did, no one else has a chance. 

```
## README ##
## This directory contains data generated during the Intro to ChIP-seq course
## Date: 

There are six subdirectories in this directory:

raw_data : contains raw data
meta:  contains...
logs:
reference_data:
results:
scripts:
```
### File naming conventions

Another aspect of staying organized is making sure that all the filenames in an analysis are as consistent as possible, and are not things like `alignment1.bam`, but more like `20170823_kd_rep1_STAR-1.4.bam`. [This link](https://datamanagement.hms.harvard.edu/file-naming-conventions) and [this slideshow](http://www2.stat.duke.edu/~rcs46/lectures_2015/01-markdown-git/slides/naming-slides/naming-slides.pdf) have some good guidelines for file naming dos and don'ts.

*** 

### Exercise

- Take a moment to create a README for the `chipseq/` folder (hint: use `vim` to create the file). Give a short description of the project and brief descriptions of the types of files you will be storing within each of the sub-directories. 
***


## Exploring the example dataset

Our goal for this session is to compare the the binding profiles of [Nanog](www.nature.com/stemcells/2009/0909/090910/full/stemcells.2009.118.html) and [Pou5f1](www.nature.com/cr/journal/v12/n5/full/7290134a.html) (Oct4). The ChIP was performed on H1 human embryonic stem cell line (h1-ESC) cells, and sequenced using Illumina. The datasets were obtained from the [HAIB TFBS ENCODE collection](http://hgdownload.cse.ucsc.edu/goldenpath/hg19/encodeDCC/wgEncodeHaibTfbs/). These 2 transcription factors are involved in **stem cell pluripotency** and one of the goals is to understand their roles, individually and together, in transriptional regulation. 

Two replicates were collected and each was divided into 3 aliquots for the following:

- Nanog IP
- Pou5f1 IP
- Control input DNA

<img src="../img/chipseq_exp_design.png" width="500">

For these 6 samples, we will be using reads from only a 32.8 Mb of chromosome 12 (chr12:1,000,000-33,800,000), so we can get through the workflow in a reasonable amount of time. 

## The ChIP-seq workflow

Below is the workflow that we will be using today. These workflows in bioinformatics adopt a plug-and-play approach in that the output of one tool can be easily used as input to another tool without any extensive configuration. The tools that are used to analyze data at different stages of the workflow are built under the assumption that the data will be provided in a specific format to facilitate a more streamlined analysis. 

<img src="../img/chip_workflow_june2017.png" width="700">	




***
*This lesson has been developed by members of the teaching team at the [Harvard Chan Bioinformatics Core (HBC)](http://bioinformatics.sph.harvard.edu/). These are open access materials distributed under the terms of the [Creative Commons Attribution license](https://creativecommons.org/licenses/by/4.0/) (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.*

